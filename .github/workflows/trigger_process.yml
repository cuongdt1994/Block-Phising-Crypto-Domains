name: Scheduled Script Execution

on:
  workflow_dispatch:
  schedule:
    - cron: "*/5 * * * *"

jobs:
  download-and-process:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          pip install requests

      - name: Download and process all sources
        run: |
          cat << 'EOF' > process_domains.py
          import os
          import json
          import requests
          import re
          from urllib.parse import urlparse

          # Cloudflare DNS IPs to exclude
          EXCLUDED_IPS = {'1.1.1.1', '1.0.0.1'}

          # Domains to exclude
          EXCLUDED_DOMAINS = {
              'raw.githubusercontent.com',
              'gist.githubusercontent.com'
          }

          def is_valid_domain(domain):
              """Validate domain format"""
              domain_pattern = r'^(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)*[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?$'
              return bool(re.match(domain_pattern, domain))

          def is_valid_ip(ip):
              """Validate IP format - improved version"""
              try:
                  parts = ip.split('.')
                  if len(parts) != 4:
                      return False
                  for part in parts:
                      if not part.isdigit():
                          return False
                      num = int(part)
                      if num < 0 or num > 255:
                          return False
                  return True
              except:
                  return False

          def is_valid_url(url):
              """Validate URL format"""
              try:
                  result = urlparse(url)
                  return all([result.scheme, result.netloc])
              except:
                  return False

          def extract_domain_from_url(url):
              """Extract domain from URL"""
              try:
                  parsed = urlparse(url)
                  return parsed.netloc
              except:
                  return None

          def process_intel_file(url):
              """Process .intel file and extract indicators"""
              indicators = []
              try:
                  response = requests.get(url, timeout=30)
                  if response.status_code == 200:
                      lines = response.text.strip().split('\n')
                      for line in lines:
                          if line.strip() and not line.startswith('#'):
                              parts = line.split('\t')
                              if len(parts) >= 2:
                                  indicator = parts[0].strip()
                                  indicator_type = parts[1].strip()
                                  
                                  # Process based on indicator type
                                  if indicator_type == 'Intel::DOMAIN':
                                      if is_valid_domain(indicator) and indicator not in EXCLUDED_DOMAINS:
                                          indicators.append(indicator)
                                  elif indicator_type == 'Intel::ADDR':
                                      if is_valid_ip(indicator) and indicator not in EXCLUDED_IPS:
                                          indicators.append(indicator)
                                  elif indicator_type == 'Intel::URL':
                                      if is_valid_url(indicator):
                                          indicators.append(indicator)
                                          # Also extract domain from URL
                                          domain = extract_domain_from_url(indicator)
                                          if domain and is_valid_domain(domain) and domain not in EXCLUDED_DOMAINS:
                                              indicators.append(domain)
              except Exception as e:
                  print(f"Error processing {url}: {e}")
              
              return indicators

          # List of .intel sources
          intel_sources = [
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/Amnesty_NSO_Domains.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/abuse-ch-threatfox-ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/abuse-ch-ipblocklist.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/abuse-ch-urlhaus.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/alienvault.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/atomspam.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/binarydefense.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/censys.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/cloudzy.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/cobaltstrike_ips.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/compromised-ips.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/cps-collected-iocs.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/drb_ra_domain.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/drb_ra_ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/drb_ra_ip_unverified.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/fangxiao.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/gru-aa25.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/illuminate.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/inversion.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/james-inthe-box.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/lockbit_ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/log4j_ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/mirai.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/openphish.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/predict_intel.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/ragnar.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/rutgers.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/sans.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/sip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/stalkerware.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/tor-exit.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/tweetfeed.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/shadowwhisperer-malware.intel'
          ]

          # Download and combine JSON sources
          print("Downloading and processing JSON sources...")
          all_json_data = []

          # Download scamsniffer domains
          try:
              scamsniffer_url = 'https://raw.githubusercontent.com/scamsniffer/scam-database/refs/heads/main/blacklist/domains.json'
              response = requests.get(scamsniffer_url)
              if response.status_code == 200:
                  scamsniffer_data = response.json()
                  # Filter out excluded domains
                  filtered_data = [domain for domain in scamsniffer_data if domain not in EXCLUDED_DOMAINS]
                  all_json_data.extend(filtered_data)
                  print(f"Added {len(filtered_data)} items from scamsniffer (excluded {len(scamsniffer_data) - len(filtered_data)} domains)")
              else:
                  print(f"Failed to download scamsniffer: {response.status_code}")
          except Exception as e:
              print(f"Error downloading scamsniffer: {e}")

          # Download metamask blacklist
          try:
              metamask_url = 'https://raw.githubusercontent.com/MetaMask/eth-phishing-detect/refs/heads/main/src/config.json'
              response = requests.get(metamask_url)
              if response.status_code == 200:
                  metamask_data = response.json()
                  blacklist_urls = metamask_data.get('blacklist', [])
                  # Filter out excluded domains
                  filtered_urls = [url for url in blacklist_urls if url not in EXCLUDED_DOMAINS]
                  all_json_data.extend(filtered_urls)
                  print(f"Added {len(filtered_urls)} items from metamask (excluded {len(blacklist_urls) - len(filtered_urls)} domains)")
              else:
                  print(f"Failed to download metamask: {response.status_code}")
          except Exception as e:
              print(f"Error downloading metamask: {e}")

          # Create directories
          os.makedirs('dist', exist_ok=True)

          # Collect all indicators
          all_indicators = set()
          
          # Add JSON sources (already filtered)
          all_indicators.update(all_json_data)
          print(f"Total from JSON sources: {len(all_json_data)}")

          # Process .intel sources
          print("Processing .intel sources...")
          for i, source in enumerate(intel_sources):
              print(f"Processing source {i+1}/{len(intel_sources)}: {source}")
              try:
                  indicators = process_intel_file(source)
                  all_indicators.update(indicators)
                  print(f"Added {len(indicators)} indicators from {source}")
              except Exception as e:
                  print(f"Error processing {source}: {e}")

          # Separate by type
          domains = set()
          ips = set()
          urls = set()

          print("Separating indicators by type...")
          for indicator in all_indicators:
              if indicator:
                  indicator = indicator.strip()
                  if is_valid_ip(indicator) and indicator not in EXCLUDED_IPS:
                      ips.add(indicator)
                  elif is_valid_url(indicator):
                      urls.add(indicator)
                      # Also extract domain from URL
                      domain = extract_domain_from_url(indicator)
                      if domain and is_valid_domain(domain) and domain not in EXCLUDED_DOMAINS:
                          domains.add(domain)
                  elif is_valid_domain(indicator) and indicator not in EXCLUDED_DOMAINS:
                      domains.add(indicator)

          # Write output files to dist directory
          print("Writing output files...")
          
          # Write domains
          with open('dist/domains.txt', 'w') as f:
              for domain in sorted(domains):
                  f.write(domain + '\n')

          # Write IPs (excluding Cloudflare DNS IPs)
          with open('dist/ips.txt', 'w') as f:
              for ip in sorted(ips):
                  if ip not in EXCLUDED_IPS:
                      f.write(ip + '\n')

          # Write URLs
          with open('dist/urls.txt', 'w') as f:
              for url in sorted(urls):
                  f.write(url + '\n')

          print(f"=== PROCESSING COMPLETE ===")
          print(f"Total indicators processed: {len(all_indicators)}")
          print(f"Domains: {len(domains)} (excluded domains: {EXCLUDED_DOMAINS})")
          print(f"IPs: {len(ips)} (excluded Cloudflare DNS IPs: {EXCLUDED_IPS})")
          print(f"URLs: {len(urls)}")

          EOF
          python process_domains.py

      - name: Move output files to lists directory
        run: |
          mkdir -p lists
          mv dist/domains.txt lists/domains
          mv dist/ips.txt lists/ips
          mv dist/urls.txt lists/urls

      - name: Clean up temporary files
        run: |
          rm -f process_domains.py
          rm -rf dist/

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add lists/
          if ! git diff --cached --quiet; then
             git commit -m "Update Blocklist: $(date +'%Y-%m-%d %H:%M:%S')"
             git push
          else
            echo "No changes to commit."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
