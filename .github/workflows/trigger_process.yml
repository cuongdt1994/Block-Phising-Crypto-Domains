name: Scheduled Script Execution

on:
  workflow_dispatch:
  schedule:
    - cron: "*/5 * * * *"

jobs:
  download-and-process:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          pip install requests

      - name: Download and process all sources
        run: |
          cat << 'EOF' > process_domains.py
          import os
          import json
          import requests
          import re
          from urllib.parse import urlparse

          def is_valid_domain(domain):
              """Validate domain format"""
              domain_pattern = r'^(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)*[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?$'
              return bool(re.match(domain_pattern, domain))

          def is_valid_ip(ip):
              """Validate IP format - improved version"""
              try:
                  parts = ip.split('.')
                  if len(parts) != 4:
                      return False
                  for part in parts:
                      if not part.isdigit():
                          return False
                      num = int(part)
                      if num < 0 or num > 255:
                          return False
                  return True
              except:
                  return False

          def is_valid_url(url):
              """Validate URL format"""
              try:
                  result = urlparse(url)
                  return all([result.scheme, result.netloc])
              except:
                  return False

          def extract_domain_from_url(url):
              """Extract domain from URL"""
              try:
                  parsed = urlparse(url)
                  return parsed.netloc
              except:
                  return None

          def process_intel_file(url):
              """Process .intel file and extract indicators"""
              indicators = []
              try:
                  response = requests.get(url, timeout=30)
                  if response.status_code == 200:
                      lines = response.text.strip().split('\n')
                      for line in lines:
                          if line.strip() and not line.startswith('#'):
                              parts = line.split('\t')
                              if len(parts) >= 2:
                                  indicator = parts[0].strip()
                                  indicator_type = parts[1].strip()
                                  
                                  # Process based on indicator type
                                  if indicator_type == 'Intel::DOMAIN':
                                      if is_valid_domain(indicator):
                                          indicators.append(indicator)
                                  elif indicator_type == 'Intel::ADDR':
                                      if is_valid_ip(indicator):
                                          indicators.append(indicator)
                                  elif indicator_type == 'Intel::URL':
                                      if is_valid_url(indicator):
                                          indicators.append(indicator)
                                          # Also extract domain from URL
                                          domain = extract_domain_from_url(indicator)
                                          if domain and is_valid_domain(domain):
                                              indicators.append(domain)
              except Exception as e:
                  print(f"Error processing {url}: {e}")
              
              return indicators

          # List of .intel sources
          intel_sources = [
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/Amnesty_NSO_Domains.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/abuse-ch-threatfox-ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/abuse-ch-ipblocklist.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/abuse-ch-urlhaus.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/alienvault.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/atomspam.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/binarydefense.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/censys.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/cloudzy.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/cobaltstrike_ips.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/compromised-ips.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/cps-collected-iocs.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/drb_ra_domain.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/drb_ra_ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/drb_ra_ip_unverified.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/fangxiao.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/gru-aa25.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/illuminate.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/inversion.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/james-inthe-box.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/lockbit_ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/log4j_ip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/mirai.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/openphish.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/predict_intel.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/ragnar.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/rutgers.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/sans.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/sip.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/stalkerware.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/tor-exit.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/tweetfeed.intel',
              'https://raw.githubusercontent.com/CriticalPathSecurity/Zeek-Intelligence-Feeds/refs/heads/master/shadowwhisperer-malware.intel'
          ]

          # Download original sources
          print("Downloading original sources...")
          try:
              scamsniffer = 'https://raw.githubusercontent.com/scamsniffer/scam-database/refs/heads/main/blacklist/domains.json'
              response = requests.get(scamsniffer)
              if response.status_code == 200:
                  with open('domains.json', 'wb') as json_file:
                      json_file.write(response.content)
              else:
                  print(f"Failed to download scamsniffer: {response.status_code}")
          except Exception as e:
              print(f"Error downloading scamsniffer: {e}")

          try:
              metammask = 'https://raw.githubusercontent.com/MetaMask/eth-phishing-detect/refs/heads/main/src/config.json'
              response = requests.get(metammask)
              if response.status_code == 200:
                  with open('config.json', 'wb') as json_file:
                      json_file.write(response.content)
              else:
                  print(f"Failed to download metamask: {response.status_code}")
          except Exception as e:
              print(f"Error downloading metamask: {e}")

          # Process original sources
          print("Processing original sources...")
          blacklist_urls = []
          domains_data = []

          # Process domains.json if exists
          if os.path.exists('domains.json'):
              try:
                  with open('domains.json', 'r') as domains_file:
                      domains_data = json.load(domains_file)
              except Exception as e:
                  print(f"Error reading domains.json: {e}")

          # Process config.json if exists
          if os.path.exists('config.json'):
              try:
                  with open('config.json', 'r') as config_file:
                      config_data = json.load(config_file)
                  blacklist_urls = config_data.get('blacklist', [])
              except Exception as e:
                  print(f"Error reading config.json: {e}")

          # Create directories
          os.makedirs('lists', exist_ok=True)
          os.makedirs('dist', exist_ok=True)

          # Collect all indicators
          all_indicators = set()
          
          # Add original sources
          all_indicators.update(blacklist_urls)
          all_indicators.update(domains_data)

          # Process .intel sources
          print("Processing .intel sources...")
          for i, source in enumerate(intel_sources):
              print(f"Processing source {i+1}/{len(intel_sources)}: {source}")
              try:
                  indicators = process_intel_file(source)
                  all_indicators.update(indicators)
                  print(f"Added {len(indicators)} indicators from {source}")
              except Exception as e:
                  print(f"Error processing {source}: {e}")

          # Separate by type
          domains = set()
          ips = set()
          urls = set()

          print("Separating indicators by type...")
          for indicator in all_indicators:
              if indicator:
                  indicator = indicator.strip()
                  if is_valid_ip(indicator):
                      ips.add(indicator)
                  elif is_valid_url(indicator):
                      urls.add(indicator)
                      # Also extract domain from URL
                      domain = extract_domain_from_url(indicator)
                      if domain and is_valid_domain(domain):
                          domains.add(domain)
                  elif is_valid_domain(indicator):
                      domains.add(indicator)

          # Write separate files
          print("Writing output files...")
          with open('dist/domains.txt', 'w') as f:
              for domain in sorted(domains):
                  f.write(domain + '\n')

          with open('dist/ips.txt', 'w') as f:
              for ip in sorted(ips):
                  f.write(ip + '\n')

          with open('dist/urls.txt', 'w') as f:
              for url in sorted(urls):
                  f.write(url + '\n')

          # Create combined blacklist
          with open('dist/blacklist.txt', 'w') as f:
              for item in sorted(all_indicators):
                  if item and item.strip():
                      f.write(item.strip() + '\n')

          print(f"Total indicators processed: {len(all_indicators)}")
          print(f"Domains: {len(domains)}")
          print(f"IPs: {len(ips)}")
          print(f"URLs: {len(urls)}")

          EOF
          python process_domains.py

      - name: Move output files
        run: |
          mv dist/blacklist.txt lists/daily
          mv dist/domains.txt lists/domains
          mv dist/ips.txt lists/ips
          mv dist/urls.txt lists/urls

      - name: Clean up untracked files
        run: |
          rm -f domains.json process_domains.py config.json
          rm -rf dist/

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add lists
          if ! git diff --cached --quiet; then
             git commit -m "Update Blocklist Phishing Site Lists ($(date +'%Y-%m-%d'))"
             git push
          else
            echo "No changes to commit."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
